# Natural Language Processing (NDAK18000U)
## Course at the University of Copenhagen

Materials from this interactive book are used throughout the Natural Language Processing course at the Department of Computer Science, University of Copenhagen. The official course description can be found [here](https://kurser.ku.dk/course/ndak18000u). Materials covered each week are listed below. The course schedule and materials are tentative and subject to minor changes. Most reading material is from [Speech and Language Processing by Jurafsky & Martin](https://web.stanford.edu/~jurafsky/slp3).

<table><tr><th>Week</th><th>Reading (before lecture)</th><th>Lecture (Tuesday)</th><th>Lab (Friday &amp; Monday)</th><th>Lab notebook</th></tr>
     <tr><td>36</td><td>
      <a href='https://web.stanford.edu/~jurafsky/slp3/2.pdf'>Chapter 2 up to end of 2.5</a><br>
      <a href='https://web.stanford.edu/~jurafsky/slp3/4.pdf'>Chapter 4 up to end of 4.5</a><br>
      <a href='https://web.stanford.edu/~jurafsky/slp3/5.pdf'>Chapter 5 up to end of 5.6</a><br>
      </td><td>3. Sep. 2024:<br>
      Course Logistics (<a href='chapters/course_logistics.ipynb'>slides</a>)<br>
      Introduction to NLP (<a href='chapters/intro_short.ipynb'>slides</a>)<br>
      Tokenisation &amp; Sentence Splitting (<a href='chapters/tokenization.ipynb'>notes</a>, <a href='chapters/tokenization_slides.ipynb'>slides</a>, <a href='exercises/tokenization.ipynb'>exercises</a>)<br>
      Text Classification (<a href='chapters/doc_classify_slides_short.ipynb'>slides</a>)<br>
      </td><td>6. &amp; 9. Sep. 2024:<br>
      Jupyter notebook setup, introduction to <a href='https://colab.research.google.com/'>Colab</a><br>
      Introduction to <a href='https://pytorch.org/tutorials/'>PyTorch</a><br>
      Project group arrangements<br>
      Questions about the course project<br>
      </td><td><a href='labs/notebooks_2024/lab_1.ipynb'>lab 1</a></td></tr>
     <tr><td>37</td><td>
      <a href='https://web.stanford.edu/~jurafsky/slp3/3.pdf'>Chapter 3 up to end of 3.5</a><br>
      <a href='https://web.stanford.edu/~jurafsky/slp3/6.pdf'>Chapter 6 up to end of 6.4</a><br>
      <a href='https://web.stanford.edu/~jurafsky/slp3/7.pdf'>Chapter 7 up to end of 7.5</a><br>
      </td><td>10. Sep. 2024:<br>
      Language Modelling (<a href='chapters/language_models_slides.ipynb'>slides</a>)<br>
      Word Embeddings (<a href='chapters/dl-representations_simple.ipynb'>slides</a>)<br>
      </td><td>13. &amp; 16. Sep. 2024:<br>
      Word representations and sentiment classification<br>
      Project help<br>
      </td><td><a href='labs/notebooks_2024/lab_2.ipynb'>lab 2</a></td></tr>
     <tr><td>38</td><td>
      <a href='https://web.stanford.edu/~jurafsky/slp3/4.pdf'>Chapter 4 up to end of 4.6</a><br>
      <a href='https://web.stanford.edu/~jurafsky/slp3/7.pdf'>Chapter 7 up to end of 7.6</a><br>
      <a href='https://web.stanford.edu/~jurafsky/slp3/9.pdf'>Chapter 9 up to end of 9.2</a></td><td>17. Sep. 2024:<br>
      Recurrent Neural Networks (<a href='chapters/rnn_slides_ucph.ipynb'>slides</a>)<br>
      Neural Language Models (<a href='chapters/dl-representations_contextual.ipynb'>slides</a>)<br>
      </td><td>20. &amp; 23. Sep. 2024:<br>
      Error analysis and explainability<br>
      Project help<br>
      </td><td><a href='labs/notebooks_2024/lab_3.ipynb'>lab 3</a></td></tr>
    <tr><td>39</td><td>
      <a href='https://web.stanford.edu/~jurafsky/slp3/8.pdf'>Chapter 8 up to end of 8.3</a><br>
      <a href='https://web.stanford.edu/~jurafsky/slp3/18.pdf'>Chapter 18 up to end of 18.2</a><br>
      </td><td>24. Sep. 2024:<br>
      Sequence Labelling (<a href='chapters/sequence_labeling_slides.ipynb'>slides</a>, <a href='chapters/sequence_labeling.ipynb'>notes</a>)<br>
      Parsing (<a href='chapters/dependency_parsing_slides_active.ipynb'>slides</a>)<br>
      </td><td>27. &amp; 30. Sep. 2024:<br>
      Sequence labelling and beam search<br>
      Project help<br>
      </td><td><a href='labs/notebooks_2024/lab_4.ipynb'>lab 4</a></td></tr>
     <tr><td>40</td><td>
      <a href='https://web.stanford.edu/~jurafsky/slp3/9.pdf'>9.8</a><br>
      <a href='https://web.stanford.edu/~jurafsky/slp3/10.pdf'>Chapter 10</a><br>
      <a href='https://web.stanford.edu/~jurafsky/slp3/11.pdf'>Chapter 11</a><br>
      </td><td>1. Oct. 2024:<br>
      Attention (<a href='chapters/attention_slides2.ipynb'>slides</a>)<br>
      Transformers (<a href='chapters/dl-representations_contextual_transformers.ipynb'>slides</a>)<br>
      </td><td>4. &amp; 7. Oct. 2024:<br>
      Language Models with <a href='https://huggingface.co/course/chapter1'>Transformers</a> and RNNs<br>
      Project help<br>
      </td><td><a href='labs/notebooks_2024/lab_5.ipynb'>lab 5</a></td></tr>
     <tr><td>41</td><td>
      <a href='https://web.stanford.edu/~jurafsky/slp3/14.pdf'>Chapter 14</a><br>
      <a href='https://web.stanford.edu/~jurafsky/slp3/14.pdf'>Chapter 19</a><br>
      </td><td>8. Oct. 2024:<br>
      Information Extraction (<a href='chapters/information_extraction_slides.ipynb'>slides</a>)<br>
      Question Answering (<a href='chapters/question_answering_slides.ipynb'>slides</a>)<br>
      </td><td>11. &amp; 21. Oct. 2024:<br>
      In-depth look at Transformers and Multilingual QA<br>
      Project help<br>
      </td><td><a href='labs/notebooks_2024/lab_6.ipynb'>lab 6</a></td></tr>
    <tr><td>43</td><td>
      <a href='https://web.stanford.edu/~jurafsky/slp3/13.pdf'>Chapter 13</a><br>
      <a href='https://shanzhenren.github.io/csci-699-replnlp-2019fall/lectures/W6-L3-Cross_Lingual_Transfer.pdf'>Wang, 2019</a><br>
      </td><td>22. Oct. 2024:<br>
      Machine Translation (<a href='chapters/nmt_slides_active.ipynb'>slides</a>)<br>
      Transfer Learning (<a href='chapters/xling_transfer_learning_slides.ipynb'>slides</a>)<br>
      </td><td>25. &amp; 28. Oct. 2024: Project help.</td><td></td></tr>
    <tr><td>44</td><td>
      <a href='https://aclanthology.org/Q19-1004.pdf'>Belinkov and Glass, 2019</a>
      </td><td>29. Oct. 2024:<br>
      Interpretability (<a href='chapters/interpretability_slides.ipynb'>slides</a>)<br>
      </td><td>1. Nov. 2024: Project help.</td><td></td></tr></table>

The easiest way to view the course content is via the static [nbviewer](https://nbviewer.jupyter.org/github/coastalcph/nlp-course/blob/master/overview.ipynb). 
To be able to make changes to the book and render it dynamically, see the [installation instructions](INSTALL.md).
